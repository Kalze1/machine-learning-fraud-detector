{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhb9xN9sHJs+VwWZH5MoUi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kalze1/machine-learning-fraud-detector/blob/Model-Building-and-Training/Model_Building_and_Training_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEGxSLqfwbfS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "id": "fJE3dT8Uw-7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "bn0KSufEwifE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXnRILu-xdd5",
        "outputId": "7477fe8e-94fe-4d1a-eaff-65ac03c348ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/machine-learning-fraud-detector/creditcard.csv')\n",
        "# X_creditcard = df.drop('Class', axis=1)\n",
        "# y_creditcard = df['Class']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_creditcard, y_creditcard, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "G9Y_p6uWwmUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['Class', 'Time'])  # Exclude 'Class' and 'Time' for features\n",
        "y = df['Class']\n",
        "\n",
        "# Split data into train and test sets (stratify to handle class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features to normalize the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"Credit Card Fraud Detection Logistic Regression v1\"):\n",
        "    # Define the Logistic Regression model\n",
        "    lr_model = LogisticRegression(max_iter=1000, random_state=42)  # Adjust max_iter for convergence\n",
        "\n",
        "    # Train the model\n",
        "    lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = lr_model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional parameters and metrics to MLflow\n",
        "    mlflow.log_param(\"model_type\", \"logistic_regression\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define the Google Drive path\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/lr_model_creditcard.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    joblib.dump(lr_model, drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9fh-ORNC3_G",
        "outputId": "73640f66-a960-4cf0-d417-1d377860f9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 17:41:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 17:41:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 17:41:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 17:41:13 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 17:41:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2024/10/27 17:41:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9991573329588147\n",
            "F1-score: 0.7241379310344828\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/lr_model_creditcard.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['Class', 'Time'])  # Exclude 'Class' and 'Time' from features\n",
        "y = df['Class']\n",
        "\n",
        "# Split data into train and test sets (stratify to handle class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"Credit Card Fraud Detection Decision Tree v1\"):\n",
        "    # Define the Decision Tree model\n",
        "    dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    dt_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = dt_model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional parameters and metrics to MLflow\n",
        "    mlflow.log_param(\"model_type\", \"decision_tree\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define the Google Drive path\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/dt_model_creditcard.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    joblib.dump(dt_model, drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm6TKMHGF-_n",
        "outputId": "e2e34975-cc8f-401e-ecb9-3f83debd3014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 17:48:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 17:48:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 17:48:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 17:48:46 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 17:48:46 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2024/10/27 17:48:46 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9991573329588147\n",
            "F1-score: 0.7551020408163265\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/dt_model_creditcard.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['Class', 'Time'])  # Exclude 'Class' and 'Time' from features\n",
        "y = df['Class']\n",
        "\n",
        "# Split data into train and test sets (stratified to handle class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"Credit Card Fraud Detection Random Forest v1\"):\n",
        "    # Define the Random Forest model\n",
        "    rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "    # Train the model\n",
        "    rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = rf_model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional parameters and metrics to MLflow\n",
        "    mlflow.log_param(\"model_type\", \"random_forest\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define the Google Drive path\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/rf_model_creditcard.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    joblib.dump(rf_model, drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0G1vDkIGYds",
        "outputId": "d8684e6d-5ec2-4a29-a42b-01bcfaecdc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 17:52:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 17:52:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 17:52:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 17:52:59 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 17:52:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2024/10/27 17:52:59 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9996137776061234\n",
            "F1-score: 0.8804347826086957\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/rf_model_creditcard.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['Class', 'Time'])  # Exclude 'Class' and 'Time' from features\n",
        "y = df['Class']\n",
        "\n",
        "# Split data into train and test sets (stratified split to handle class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"Credit Card Fraud Detection Gradient Boosting v1\"):\n",
        "    # Define the Gradient Boosting model\n",
        "    gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    gb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = gb_model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional parameters and metrics to MLflow\n",
        "    mlflow.log_param(\"model_type\", \"gradient_boosting\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define the Google Drive path\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/gb_model_creditcard.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    joblib.dump(gb_model, drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYZFj5wZG8zc",
        "outputId": "51a631dc-fa71-45cd-bf5e-9107af58acee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 17:58:33 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 17:58:33 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 17:58:33 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 17:58:33 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 17:58:33 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2024/10/27 17:58:33 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9983146659176293\n",
            "F1-score: 0.2727272727272727\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/gb_model_creditcard.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['Class', 'Time'])  # Exclude 'Class' and 'Time' from features\n",
        "y = df['Class']\n",
        "\n",
        "# Split data into train and test sets (stratify to handle class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"Credit Card Fraud Detection MLP v1\"):\n",
        "    # Define the MLP model\n",
        "    mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    mlp_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = mlp_model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional parameters and metrics to MLflow\n",
        "    mlflow.log_param(\"model_type\", \"mlp\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define the Google Drive path\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/mlp_model_creditcard.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    joblib.dump(mlp_model, drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYPtUnSsKfqB",
        "outputId": "1757c3ff-3eea-4874-f785-2797e5051fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 18:08:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 18:08:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 18:08:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 18:08:59 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 18:08:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2024/10/27 18:08:59 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9994908886626171\n",
            "F1-score: 0.8465608465608465\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/mlp_model_creditcard.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['Class', 'Time'])  # Exclude 'Class' and 'Time' from features\n",
        "y = df['Class']\n",
        "\n",
        "# Split data into train and test sets (stratify to handle class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the neural network model (FCNN)\n",
        "fcnn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "fcnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define Google Drive path for saving model\n",
        "drive_save_path = '/content/drive/MyDrive/machine-learning-fraud-detector/fcnn_model_creditcard.h5'\n",
        "\n",
        "with mlflow.start_run(run_name=\"FCNN Model (Credit Card Fraud Detection)\"):\n",
        "    # Log model parameters\n",
        "    mlflow.log_param(\"model_type\", \"fcnn\")\n",
        "    mlflow.log_param(\"source\", \"trained_from_scratch\")\n",
        "\n",
        "    # Train the model\n",
        "    fcnn_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    test_loss, test_accuracy = fcnn_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "    # Log test metrics to MLflow\n",
        "    mlflow.log_metric(\"test_loss\", test_loss)\n",
        "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
        "\n",
        "    # Generate predictions and evaluate additional metrics\n",
        "    y_pred = fcnn_model.predict(X_test_scaled)\n",
        "    y_pred_classes = (y_pred > 0.5).astype(\"int32\")  # Convert probabilities to binary class predictions\n",
        "\n",
        "    # Calculate sklearn metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    f1 = f1_score(y_test, y_pred_classes)\n",
        "\n",
        "    print(f\"Sklearn Accuracy: {accuracy}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    # Log sklearn accuracy and F1-score\n",
        "    mlflow.log_metric(\"sklearn_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Generate and log the classification report\n",
        "    class_report = classification_report(y_test, y_pred_classes)\n",
        "    print(f\"Classification Report: \\n{class_report}\")\n",
        "\n",
        "    # Save the classification report as an artifact\n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(class_report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\")\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    fcnn_model.save(drive_save_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_save_path}\")\n",
        "\n",
        "print(\"Model training, evaluation, and logging completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "grxnN3V_LDli",
        "outputId": "c4263ec6-621f-48dd-ae4a-1c5d9791d72e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2024/10/27 18:28:03 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m5687/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0163 - val_accuracy: 0.9994 - val_loss: 0.0036\n",
            "Epoch 2/10\n",
            "\u001b[1m5677/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0028"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9995 - val_loss: 0.0032\n",
            "Epoch 3/10\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9994 - val_loss: 0.0035\n",
            "Epoch 4/10\n",
            "\u001b[1m5678/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0022"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9995 - val_loss: 0.0030\n",
            "Epoch 5/10\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9995 - val_loss: 0.0035\n",
            "Epoch 6/10\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9994 - val_loss: 0.0032\n",
            "Epoch 7/10\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9994 - val_loss: 0.0034\n",
            "Epoch 8/10\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9995 - val_loss: 0.0031\n",
            "Epoch 9/10\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9996 - val_loss: 0.0033\n",
            "Epoch 10/10\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9994 - val_loss: 0.0039\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Test Loss: 0.0037981823552399874\n",
            "Test Accuracy: 0.9992626905441284\n",
            "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Accuracy: 0.9992626663389628\n",
            "F1 Score: 0.7857142857142857\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.79      0.79      0.79        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.89      0.89      0.89     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/fcnn_model_creditcard.h5\n",
            "Model training, evaluation, and logging completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = df.drop(columns=['Class'])  # All features except the 'Class' column\n",
        "y = df['Class']  # Target variable (fraud or not)\n",
        "\n",
        "# Scale the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets (consider stratification for imbalanced classes)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "# Define RNN model architecture\n",
        "with mlflow.start_run(run_name=\"RNN Model for Fraud Detection\"):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=True),  # Adjust LSTM units if needed\n",
        "        LSTM(32),  # Adjust LSTM units\n",
        "        Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Reshape the data for RNN input\n",
        "    X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    # Make predictions and calculate F1 score\n",
        "    y_pred = (model.predict(X_test_reshaped) > 0.5).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional metrics and parameters\n",
        "    mlflow.log_param(\"model_type\", \"rnn\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define Google Drive path\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/rnn_fraud_model.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    model.save(drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "o3IflnJ6RbEE",
        "outputId": "6306eb8c-7631-4d4b-b8b2-59ff6f79b8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 18:47:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 18:47:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 18:47:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 18:47:11 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 18:47:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "2024/10/27 18:47:13 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0193\n",
            "Epoch 2/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0123\n",
            "Epoch 3/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0129\n",
            "Epoch 4/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0131\n",
            "Epoch 5/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0133\n",
            "Epoch 6/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0127\n",
            "Epoch 7/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0126\n",
            "Epoch 8/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0119\n",
            "Epoch 9/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0136\n",
            "Epoch 10/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0132\n",
            "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0104\n",
            "Accuracy: 0.9982795715332031\n",
            "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.0\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/rnn_fraud_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = df.drop(columns=['Class'])  # All features except the 'Class' column\n",
        "y = df['Class']  # Target variable (fraud or not)\n",
        "\n",
        "# Scale the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets (consider stratified split for imbalanced classes)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "with mlflow.start_run(run_name=\"LSTM Model for Fraud Detection\"):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=True),  # LSTM to handle numerical sequences\n",
        "        LSTM(32),  # Adjust LSTM units as needed\n",
        "        Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Reshape the data to fit LSTM input shape (samples, timesteps, features)\n",
        "    X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    # Make predictions and calculate F1 score\n",
        "    y_pred = (model.predict(X_test_reshaped) > 0.5).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional metrics and parameters\n",
        "    mlflow.log_param(\"model_type\", \"lstm\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define Google Drive path to save the model\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/lstm_fraud_model.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    model.save(drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "WBqqIQqHR-WM",
        "outputId": "44187484-b43c-4623-c331-62eae5d7a1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 19:00:30 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 19:00:30 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 19:00:30 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 19:00:30 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 19:00:30 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "2024/10/27 19:00:31 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0196\n",
            "Epoch 2/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0123\n",
            "Epoch 3/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0123\n",
            "Epoch 4/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0131\n",
            "Epoch 5/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0132\n",
            "Epoch 6/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0128\n",
            "Epoch 7/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0119\n",
            "Epoch 8/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0129\n",
            "Epoch 9/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0130\n",
            "Epoch 10/10\n",
            "\u001b[1m7121/7121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0123\n",
            "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0104\n",
            "Accuracy: 0.9982795715332031\n",
            "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.0\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/lstm_fraud_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/machine-learning-fraud-detector/preprocessed1.csv')"
      ],
      "metadata": {
        "id": "PSLev-YUZXPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# Drop irrelevant or redundant columns\n",
        "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.2', 'transaction_velocity'])\n",
        "\n",
        "# Handle categorical columns: 'device_id', 'country', 'signup_time', 'purchase_time'\n",
        "# Convert 'signup_time' and 'purchase_time' to timestamp and extract useful features like hour, day, etc.\n",
        "df['signup_time'] = pd.to_datetime(df['signup_time'])\n",
        "df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
        "\n",
        "# Extract features from datetime columns (hour, day, etc.)\n",
        "df['signup_hour'] = df['signup_time'].dt.hour\n",
        "df['purchase_hour'] = df['purchase_time'].dt.hour\n",
        "df['signup_day'] = df['signup_time'].dt.dayofweek\n",
        "df['purchase_day'] = df['purchase_time'].dt.dayofweek\n",
        "\n",
        "# Drop original datetime columns\n",
        "df = df.drop(columns=['signup_time', 'purchase_time'])\n",
        "\n",
        "# Encode categorical columns\n",
        "encoder = LabelEncoder()\n",
        "df['device_id'] = encoder.fit_transform(df['device_id'])\n",
        "df['country'] = encoder.fit_transform(df['country'])\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = df.drop(columns=['class'])  # All features except the 'class' column\n",
        "y = df['class']  # Target variable (fraud or not)\n",
        "\n",
        "# Scale the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets (stratified split for imbalanced classes)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "with mlflow.start_run(run_name=\"LSTM Model for Fraud Detection\"):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=True),  # LSTM to handle numerical sequences\n",
        "        LSTM(32),  # Adjust LSTM units as needed\n",
        "        Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Reshape the data to fit LSTM input shape (samples, timesteps, features)\n",
        "    X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    # Make predictions and calculate F1 score\n",
        "    y_pred = (model.predict(X_test_reshaped) > 0.5).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional metrics and parameters\n",
        "    mlflow.log_param(\"model_type\", \"lstm\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define Google Drive path to save the model\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/lstm_fraud_model_for_fraud_data.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    model.save(drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "MXwhPok6ZbFc",
        "outputId": "b4003d85-396f-4fe4-ba29-8b738567132a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 19:21:06 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 19:21:06 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 19:21:06 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 19:21:06 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 19:21:06 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "2024/10/27 19:21:06 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9058 - loss: 0.3128\n",
            "Epoch 2/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9245 - loss: 0.2362\n",
            "Epoch 3/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.1996\n",
            "Epoch 4/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9522 - loss: 0.1895\n",
            "Epoch 5/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.1829\n",
            "Epoch 6/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9545 - loss: 0.1835\n",
            "Epoch 7/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9543 - loss: 0.1841\n",
            "Epoch 8/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9559 - loss: 0.1789\n",
            "Epoch 9/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.1823\n",
            "Epoch 10/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9554 - loss: 0.1801\n",
            "\u001b[1m808/808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9558 - loss: 0.1809\n",
            "Accuracy: 0.9564072489738464\n",
            "\u001b[1m808/808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.7046169989506821\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/lstm_fraud_model_for_fraud_data.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = df.drop(columns=['class'])  # All features except the 'class' column (target variable)\n",
        "y = df['class']  # Target variable (fraud or not)\n",
        "\n",
        "# Scale the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets (stratified split for imbalanced classes)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "# Define RNN model architecture\n",
        "with mlflow.start_run(run_name=\"RNN Model for Fraud Detection\"):\n",
        "    model = Sequential([\n",
        "        LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=True),  # LSTM to handle numerical sequences\n",
        "        LSTM(32),  # Adjust LSTM units if needed\n",
        "        Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Reshape the data for RNN input shape (samples, timesteps, features)\n",
        "    X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    # Make predictions and calculate F1 score\n",
        "    y_pred = (model.predict(X_test_reshaped) > 0.5).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional metrics and parameters to MLflow\n",
        "    mlflow.log_param(\"model_type\", \"rnn\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define the Google Drive path to save the model\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/rnn_fraud_model_for_fraud_data.h5'\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    model.save(drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "wj43EDhMcKh1",
        "outputId": "22c42a93-27a6-4c99-e3c5-12a9d4a6f6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 19:30:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 19:30:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 19:30:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 19:30:12 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 19:30:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "2024/10/27 19:30:12 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9017 - loss: 0.3142\n",
            "Epoch 2/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 8ms/step - accuracy: 0.9232 - loss: 0.2403\n",
            "Epoch 3/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.2024\n",
            "Epoch 4/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9528 - loss: 0.1873\n",
            "Epoch 5/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1867\n",
            "Epoch 6/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.9547 - loss: 0.1827\n",
            "Epoch 7/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9537 - loss: 0.1856\n",
            "Epoch 8/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.1821\n",
            "Epoch 9/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.1828\n",
            "Epoch 10/10\n",
            "\u001b[1m3229/3229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - accuracy: 0.9556 - loss: 0.1799\n",
            "\u001b[1m808/808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1794\n",
            "Accuracy: 0.95625239610672\n",
            "\u001b[1m808/808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.7040335254059717\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/rnn_fraud_model_for_fraud_data.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "# Display the first few rows of the dataset to verify loading\n",
        "print(df.head())\n",
        "\n",
        "# Define features and target variable\n",
        "# Exclude 'Class' (target) and 'Time' from features\n",
        "X = df.drop(columns=['class'])\n",
        "y = df['class']  # Target variable (fraud or not)\n",
        "\n",
        "# Split data into train and test sets (stratify to handle class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the Fully Connected Neural Network (FCNN) model\n",
        "fcnn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Input layer\n",
        "    Dense(32, activation='relu'),  # Hidden layer\n",
        "    Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "fcnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the Google Drive path for saving the model\n",
        "drive_save_path = '/content/drive/MyDrive/machine-learning-fraud-detector/fcnn_model_creditcard.h5'\n",
        "\n",
        "# Start MLflow run\n",
        "with mlflow.start_run(run_name=\"FCNN Model (Credit Card Fraud Detection)\"):\n",
        "    # Log model parameters\n",
        "    mlflow.log_param(\"model_type\", \"fcnn\")\n",
        "    mlflow.log_param(\"source\", \"trained_from_scratch\")\n",
        "\n",
        "    # Train the model\n",
        "    fcnn_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    test_loss, test_accuracy = fcnn_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "    # Log test metrics to MLflow\n",
        "    mlflow.log_metric(\"test_loss\", test_loss)\n",
        "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
        "\n",
        "    # Generate predictions and evaluate additional metrics\n",
        "    y_pred = fcnn_model.predict(X_test_scaled)\n",
        "    y_pred_classes = (y_pred > 0.5).astype(\"int32\")  # Convert probabilities to binary class predictions\n",
        "\n",
        "    # Calculate sklearn metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    f1 = f1_score(y_test, y_pred_classes)\n",
        "\n",
        "    print(f\"Sklearn Accuracy: {accuracy}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    # Log sklearn accuracy and F1-score\n",
        "    mlflow.log_metric(\"sklearn_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Generate and log the classification report\n",
        "    class_report = classification_report(y_test, y_pred_classes)\n",
        "    print(f\"Classification Report: \\n{class_report}\")\n",
        "\n",
        "    # Save the classification report as an artifact\n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(class_report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\")\n",
        "\n",
        "    # Save the model to Google Drive\n",
        "    fcnn_model.save(drive_save_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_save_path}\")\n",
        "\n",
        "print(\"Model training, evaluation, and logging completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9WLfs4u9eF5o",
        "outputId": "61882903-f650-4dd8-8d5d-a7d2f10a5387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id  purchase_value  device_id  source  browser  sex  age  ip_address  \\\n",
            "0   247547        0.262069      46780       2        4    0   30    16778864   \n",
            "1   220737        0.041379      70073       2        0    0   34    16842045   \n",
            "2   390400        0.241379      53448       0        2    1   29    16843656   \n",
            "3    69592        0.317241      92195       1        0    0   30    16938732   \n",
            "4   174987        0.289655     107434       2        0    0   37    16971984   \n",
            "\n",
            "   class  country  time_diff  user_transaction_frequency  hour_of_day  \\\n",
            "0      0        7   0.350330                         0.0            3   \n",
            "1      0      162   0.118792                         0.0           20   \n",
            "2      0       36   0.192664                         0.0           23   \n",
            "3      0       36   0.736971                         0.0           16   \n",
            "4      0      162   0.988581                         0.0            4   \n",
            "\n",
            "   day_of_week  signup_hour  purchase_hour  signup_day  purchase_day  \n",
            "0            6            3              3           6             6  \n",
            "1            2           14             20           2             2  \n",
            "2            5           20             23           3             5  \n",
            "3            5            6             16           1             5  \n",
            "4            1           12              4           1             1  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2024/10/27 19:41:17 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2683 - val_accuracy: 0.9549 - val_loss: 0.1854\n",
            "Epoch 2/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.1927 - val_accuracy: 0.9569 - val_loss: 0.1760\n",
            "Epoch 3/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9547 - loss: 0.1834 - val_accuracy: 0.9578 - val_loss: 0.1750\n",
            "Epoch 4/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1849 - val_accuracy: 0.9581 - val_loss: 0.1739\n",
            "Epoch 5/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1858 - val_accuracy: 0.9577 - val_loss: 0.1748\n",
            "Epoch 6/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9547 - loss: 0.1825 - val_accuracy: 0.9578 - val_loss: 0.1751\n",
            "Epoch 7/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.1820 - val_accuracy: 0.9582 - val_loss: 0.1728\n",
            "Epoch 8/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.1813 - val_accuracy: 0.9582 - val_loss: 0.1728\n",
            "Epoch 9/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.1831 - val_accuracy: 0.9577 - val_loss: 0.1755\n",
            "Epoch 10/10\n",
            "\u001b[1m2583/2583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1807 - val_accuracy: 0.9577 - val_loss: 0.1762\n",
            "Test Loss: 0.17974555492401123\n",
            "Test Accuracy: 0.9561362862586975\n",
            "\u001b[1m808/808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Accuracy: 0.9561362756484708\n",
            "F1 Score: 0.7037908496732026\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98     23376\n",
            "           1       0.98      0.55      0.70      2454\n",
            "\n",
            "    accuracy                           0.96     25830\n",
            "   macro avg       0.97      0.77      0.84     25830\n",
            "weighted avg       0.96      0.96      0.95     25830\n",
            "\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/fcnn_model_creditcard.h5\n",
            "Model training, evaluation, and logging completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "# Load the dataset (if not already loaded)\n",
        "# df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['class'])  # Exclude 'Class' from features\n",
        "y = df['class']  # Target variable\n",
        "\n",
        "# Scale the features using MinMaxScaler (same as the LSTM model)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets (stratified to handle class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Start MLflow autologging\n",
        "mlflow.autolog()\n",
        "\n",
        "with mlflow.start_run(run_name=\"Logistic Regression for Fraud Detection\"):\n",
        "    # Define the Logistic Regression model\n",
        "    lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    lr_model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = lr_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # Log additional parameters and metrics to MLflow\n",
        "    mlflow.log_param(\"model_type\", \"logistic_regression\")\n",
        "    mlflow.log_metric(\"final_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # Define the Google Drive path (same folder as LSTM model)\n",
        "    drive_model_path = '/content/drive/MyDrive/machine-learning-fraud-detector/lr_model_fraud_data.pkl'\n",
        "\n",
        "    # Save the Logistic Regression model to Google Drive using joblib\n",
        "    joblib.dump(lr_model, drive_model_path)\n",
        "    print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBzM1S_rhoxC",
        "outputId": "bd2bf54b-b258-47e4-844d-fc0b1e893fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 19:50:25 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2024/10/27 19:50:25 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2024/10/27 19:50:25 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/10/27 19:50:25 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2024/10/27 19:50:25 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2024/10/27 19:50:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9049941927990709\n",
            "F1-score: 0.0\n",
            "Model saved to Google Drive at: /content/drive/MyDrive/machine-learning-fraud-detector/lr_model_fraud_data.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap lime"
      ],
      "metadata": {
        "id": "odST7HX_ixdk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}